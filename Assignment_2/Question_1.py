# -*- coding: utf-8 -*-
"""Assignment2_Question1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VQ2AqN8actQ-WWJI51sCBSJfuyDkhUMV
"""

!pip install pydrive
!pip install hmmlearn
!pip install librosa
!pip install import-ipynb

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)
from google.colab import drive as dr
dr.mount('/content/drive')

import matplotlib.pyplot as plt
import numpy as np
from numpy import genfromtxt
# np.random.seed(1213)
my_data = genfromtxt('/content/drive/My Drive/PrmlAssignment/PRML_assignment1/Datasets/Dataset3.csv', delimiter=',')
print(my_data.shape)
plt.scatter(my_data[:,0],my_data[:,1])
plt.show()

#kmeans clustering
def findkmeans(mydata,clusters):
    global my_data
    maxvalue = np.amax(mydata,axis = 0 )
    minvalue = np.amin(mydata ,axis = 0)
    dimension_of_data = len(mydata[0])
    # print("max",maxvalue,"min",minvalue)
    centers = []
    for i in range(dimension_of_data):
        centers.append(np.random.uniform(low=minvalue[i],  high = maxvalue[i], size=(clusters,)))
    centers = np.array(centers).T
    # print("centers",centers)
    initial_error = 100000000000
    error_difference_limit = .000009
    count  = 0
    total_error_difference = 100000000
    error_in_itearation = []
    x_axis = []
    while(total_error_difference>error_difference_limit):
        # print("rajan")
        K_cluster_bucket_of_points = []
        for i in range(clusters):
            K_cluster_bucket_of_points.append([])
        K_cluster_bucket_of_points_for_error = []
        for i in range(clusters):
            K_cluster_bucket_of_points_for_error.append([])
        x_axis.append(count)
        count = count +1
        # print("count",count)
        sum_of_cluster_points = np.zeros((clusters,dimension_of_data))
        count_in_cluster = np.zeros(clusters)
    
        for i in range(len(mydata)):
            distance = []
            for k in range(clusters):
                yup = np.subtract(mydata[i],centers[k])
                distance.append(np.linalg.norm(yup))
                

            p = np.argmin(distance)
            # print("p",p)
            count_in_cluster[p]= count_in_cluster[p] +1
            # print("rajan",sum_of_cluster_points[p],"cluster",p)
            sum_of_cluster_points[p] = np.sum([sum_of_cluster_points[p] ,mydata[i]], axis = 0)
            K_cluster_bucket_of_points[p].append(my_data[i])
            K_cluster_bucket_of_points_for_error[p].append(mydata[i])
       
            

    # print("binarylist",binarylist)
        total_error = 0
        for cl in range(clusters):
            
            for point in K_cluster_bucket_of_points_for_error[cl]:
                yup = np.subtract(point,centers[cl])
                c= np.linalg.norm(yup)
                
                total_error= total_error +c
        # print(total_error)
        
        error_in_itearation.append(total_error)
        total_error_difference = np.absolute(initial_error-total_error)
        initial_error = total_error
        print(initial_error) 
                


        
        new_center = []
        for i in range(clusters):
            new_center.append(sum_of_cluster_points[i]/count_in_cluster[i])

        centers = new_center

    return centers,K_cluster_bucket_of_points,error_in_itearation,x_axis

#predicting cluster for testpoint
def find_cluster_for_test_point(centers,datapoint,clusters):
    distance = []
    for k in range(clusters):
        yup = np.subtract(datapoint,centers[k])
        distance.append(np.linalg.norm(yup))
    p = np.argmin(distance)
    return p

clusters = 5
for j in range(1):
    centers,K_cluster_bucket_of_points,error_in_itearation,x_axis = findkmeans(my_data,clusters)

    plt.subplots()
    plt.plot(x_axis,error_in_itearation)
    plt.xlabel('iterations')
    plt.ylabel('error')
    plt.show()
    plt.close()

    for i in range(clusters):
        s = np.array(K_cluster_bucket_of_points[i])

        plt.scatter(s[:,0],s[:,1])

    plt.show()
    plt.close()
  



# print(t)

def plot_vornoi(mydata,centers,clusters):
    maxvalue = np.amax(mydata,axis = 0 )
    minvalue = np.amin(mydata ,axis = 0)
    x = np.linspace(minvalue[0],maxvalue[0],1000)
    y = np.linspace(minvalue[1],maxvalue[1],1000)
    X, Y = np.meshgrid(x,y)
    final = []
    for i in range(len(X)):
        lis = []
        for j in range(len(X)):
            c = [X[i][j],Y[i][j]]
            p = find_cluster_for_test_point(centers,c,clusters)
            lis.append(p)
        final.append(lis)
    plt.scatter(X,Y,c = final)
    for i in range(clusters):
        plt.scatter(centers[i][0],centers[i][1])

    
    plt.show()

    return X,Y

x,y = plot_vornoi(my_data,centers,clusters)
x.shape



kernel_matrix = []
delta = .4
for dati in my_data:
  small_matrix = []
  for datj in my_data:
    # r = (dati[0]**2 + dati[1]**2)*(datj[0]**2 + datj[1]**2)
    r = np.exp(- np.linalg.norm(np.subtract(dati,datj)) ** 2 / (2. * delta ** 2))
    small_matrix.append(r)
  kernel_matrix.append(small_matrix)

D = []
d= np.sum(np.array(kernel_matrix), axis = 1)
for i in range(len(kernel_matrix)):
    a =  np.zeros(len(kernel_matrix))
    a[i] = d[i]
    D.append(a)

D = np.linalg.inv(D)
D = np.sqrt(D)

L = np.matmul(D,np.matmul(np.array(kernel_matrix),D))
a, b = np.linalg.eigh(L)
# idx = a.argsort()[::-1]   
# a = a[idx]
# b = b[:,idx]
b = b[:,996:]
p = np.linalg.norm(b,axis=1)
# print(p)
b = np.divide(b.T,p).T

# print(len(b[:,0:2]))
clusters =4
centers,K_cluster_bucket_of_points,error_in_itearation,x_axis = findkmeans(b,clusters)

print(np.array(centers).shape)
for i in range(clusters):
    s = np.array(K_cluster_bucket_of_points[i])
    # print(s)
    # print(s[:,0].shape,s[:,1].shape)
    plt.scatter(s[:,0],s[:,1])
plt.show()
plt.close()